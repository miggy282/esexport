#!/usr/bin/env python
__author__ = "Miguel Sullivan"
""" Export Elasticsearch data to plain text"""

import sys, json
import requests 
import argparse
import time

def cmd_args():
    parser = argparse.ArgumentParser(description='Export Elasticsearch Logs')
    parser.add_argument('-H', '--host',   help='Elasticsearch host')
    parser.add_argument('-i', '--index',  help='Index name')
    parser.add_argument('-t', '--trange', help='timerange from and to eg dd/mm/YY 00:00:32 to dd/mm/YY/ 00:00:32')
    parser.add_argument('-q', '--query', help='lucene query')
    args = parser.parse_args()

    host = args.host
    query  = args.query
    index = args.index
    ts, te  = args.trange.split("to")

    # Convert time to eppoch
    pattern = '%d/%m/%Y %H:%M:%S'
    t_start = int(time.mktime(time.strptime(ts.strip(), pattern))) * 1000
    t_end   = int(time.mktime(time.strptime(te.strip(), pattern))) * 1000

    # Return Dict 
    args = {
        'host': host, 
        'index': index, 
        'time_start': t_start, 
        'time_end': t_end, 
        'query': query
    } 
    return args

# Initlise command line arguments 
cmd = cmd_args()

# Build JSON query
payload = json.dumps(
{
  "query": {
    "filtered": {
      "query": {
        "bool": {
          "should": [
            {
              "query_string": {
                "query": cmd['query']
              }
            }
          ]
        }
      },
      "filter": {
        "bool": {
          "must": [
            {
              "range": {
                "@timestamp": {
                  "from": cmd['time_start'],
                  "to": cmd['time_end']
                }
              }
            }
          ]
        }
      }
    }
  },
  "highlight": {
    "fields": {},
    "fragment_size": 2147483647,
    "pre_tags": [
      "@start-highlight@"
    ],
    "post_tags": [
      "@end-highlight@"
    ]
  },
  "size": 5000,
  "sort": [
    {
      "@timestamp": {
        "order": "desc",
        "ignore_unmapped": "true"
      }
    },
  ]
})
print payload
# Extract lines based on address ['hits']['hits'][index]['_source']['message']

def extract_lines(data):
    raw = data
    for key in range(len(raw['hits']['hits'])):
       print  json.dumps(raw['hits']['hits'][key]["_source"]["message"]).strip()
      
def scroll_continue(s_id):
    querystring = {
                   "scroll_id": s_id,
                   "scroll" : "1m"
                  }

    r = requests.get(cmd['host'] + ":9200/_search/scroll", params=querystring, timeout=60.001)
    json_data = json.loads(r.text)
    return json_data

if __name__ == '__main__':
    # requests  arguments 
    url = cmd['host'] + ":9200/" + cmd['index'] + "/_search"
    headers = {'Content-Type': "application/json; charset=UTF-8"}
    querystring = {"scroll":"1m"}

    # Initial Request
    try:
       r = requests.post(url, data=payload, headers=headers, params=querystring, timeout=60.001)
       print r.text
       print r
       if r.status_code == 200:
          print 'Submitting Query ...'
          s_id  = json.loads(r.text)['_scroll_id']
          hits  = json.loads(r.text)
       else:
         raise Exception("HTTPError, received status code: " + str(r.status_code))

       # Only scroll if need be
       # If theres hits in the initial request we're going to extract them 
       if hits['hits']['hits']:
          extract_lines(hits)
          # Contintue scrolling if theres more hits
          while True:
             try:
                # Return _scroll results to variable
                hits = scroll_continue(s_id)
             except requests.exceptions.RequestException as e:
                print  "Error: {}".format(e), "Failed"
                sys.exit(1)
             if 'hits' in hits:
                extract_lines(hits)
             else: 
                # Scrolls should be explicitly cleared as soon as the scroll is not being used anymore 
                payload = {"scroll":s_id}
                requests.delete(cmd['host'] + ":9200/" + "_search/scroll", data=payload, headers=headers)
                print "Completed! End of logs"
                break
                sys.exit(0)
       else:
          print "No hits found!"

    except requests.exceptions.RequestException as e:
       print  "Error: {}".format(e), "Failed"
   
